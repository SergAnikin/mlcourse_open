{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Открытый курс по машинному обучению. Сессия № 2\n",
    "Авторы материала: Павел Нестеров. Материал распространяется на условиях лицензии [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Можно использовать в любых целях (редактировать, поправлять и брать за основу), кроме коммерческих, но с обязательным упоминанием автора материала."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Домашняя работа №4\n",
    "## <center> Логистическая регрессия в задаче тегирования вопросов StackOverflow\n",
    "\n",
    "**Надо вывести формулы, где это просится (да, ручка и бумажка), заполнить код в клетках и выбрать ответы в [веб-форме](https://docs.google.com/forms/d/1I_ticU8rpeoGJjsBUcaInpvgdxdq60hV7IcSvo4rlGo/).**\n",
    "\n",
    "## 0. Описание задачи\n",
    "\n",
    "В этой домашней работе мы с вами изучим и запрограммируем модель для прогнозирования тегов по тексту вопроса на базе многоклассовой логистической регрессии. В отличие от обычной постановки задачи классификации (multiclass), в данном случае один пример может принадлежать одновременно к нескольким классам (multilabel). Мы будем реализовывать онлайн версию алгоритма мультиклассовой классификации.\n",
    "\n",
    "Мы будем использовать небольшую выборку из протеггированных вопросов с сайта StackOverflow размером в 125 тысяч примеров (около 150 Мб, скачайте по [этой](https://drive.google.com/open?id=0B4bl7YMqDnViYVo0V2FubFVhMFE) ссылке).\n",
    "\n",
    "PS: Можно показать, что такая реализация совсем не эффективная и проще было бы использовать векторизированные вычисления. Для данного датасета так и есть. Но на самом деле подобные реализации используются в жизни, но естественно, написаны они не на Python. Например, в онлайн моделях прогнозирования [CTR](https://en.wikipedia.org/wiki/Click-through_rate) юзеру показывается баннер, затем в зависимости от наличия клика происходит обновление параметров модели. В реальной жизни параметров модели может быть несколько сотен миллионов, а у юзера из этих ста миллионов от силы сто или тысяча параметров отличны от нуля, векторизировать такие вычисления не очень эффективно. Обычно все это хранится в огромных кластерах в in-memory базах данных, а обработка пользователей происходит распределенно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"dark\")\n",
    "plt.rcParams['figure.figsize'] = 16, 12\n",
    "from tqdm import tqdm_notebook\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# поменяйте на свой путь\n",
    "DS_FILE_NAME = '../../../data/stackoverflow_sample_125k.tsv'\n",
    "TAGS_FILE_NAME = 'data/top10_tags.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'javascript', 'python', 'java', 'android', 'php', 'c++', 'c#', 'jquery', 'ios', 'html'}\n"
     ]
    }
   ],
   "source": [
    "top_tags = []\n",
    "with open(TAGS_FILE_NAME, 'r') as f:\n",
    "    for line in f:\n",
    "        top_tags.append(line.strip())\n",
    "top_tags = set(top_tags)\n",
    "print(top_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Многоклассовая логистическая регрессия\n",
    "\n",
    "Вспомним, как получается логистическая регрессия для двух классов $\\left\\{0, 1\\right\\}$, вероятность принадлежности объекта к классу $1$ выписывается по теореме Байеса:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "p\\left(c = 1 \\mid \\vec{x}\\right) &=& \\dfrac{p\\left(\\vec{x} \\mid c = 1\\right)p\\left(c = 1\\right)}{p\\left(\\vec{x} \\mid c = 1\\right)p\\left(c = 1\\right) + p\\left(\\vec{x} \\mid c = 0\\right)p\\left(c = 0\\right)} \\\\\n",
    "&=& \\dfrac{1}{1 + e^{-a}} \\\\\n",
    "&=& \\sigma\\left(a\\right)\n",
    "\\end{array}$$\n",
    "где:\n",
    "- $\\vec{x}$ – вектор признаков объекта\n",
    "- $\\sigma$ – обозначение функции логистического сигмоида при скалярном аргументе\n",
    "- $a = \\log \\frac{p\\left(\\vec{x} \\mid c = 1\\right)p\\left(c = 1\\right)}{p\\left(\\vec{x} \\mid c = 0\\right)p\\left(c = 0\\right)} = \\sum_{i=0}^M w_i x_i$ – это отношение мы моделируем линейной функцией от признаков объекта и параметров модели\n",
    "\n",
    "Данное выражение легко обобщить до множества из $K$ классов, изменится только знаменатель в формуле Байеса. Запишем вероятность принадлежности объекта к классу $k$:\n",
    "$$\\large \\begin{array}{rcl}\n",
    "p\\left(c = k \\mid \\vec{x}\\right) &=& \\dfrac{p\\left(\\vec{x} \\mid c = k\\right)p\\left(c = k\\right)}{\\sum_{i=1}^K p\\left(\\vec{x} \\mid c = i\\right)p\\left(c = i\\right)} \\\\\n",
    "&=& \\dfrac{e^{z_k}}{\\sum_{i=1}^{K}e^{z_i}} \\\\\n",
    "&=& \\sigma_k\\left(\\vec{z}\\right)\n",
    "\\end{array}$$\n",
    "где:\n",
    "- $\\sigma_k$ – обозначение функции softmax при векторном аргументе\n",
    "- $z_k = \\log p\\left(\\vec{x} \\mid c = k\\right)p\\left(c = k\\right) = \\sum_{i=0}^M w_{ki} x_i$ – это выражение моделируется линейной функцией от признаков объекта и параметров модели для класса $k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для моделирования полного правдоподобия примера мы используем [категориальное распределение](https://en.wikipedia.org/wiki/Categorical_distribution), а лучше его логарифм (для удобства):\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\mathcal{L} = \\log p\\left({\\vec{x}}\\right) &=& \\log \\prod_{i=1}^K \\sigma_i\\left(\\vec{z}\\right)^{y_i} \\\\\n",
    "&=& \\sum_{i=1}^K y_i \\log \\sigma_i\\left(\\vec{z}\\right)\n",
    "\\end{array}$$\n",
    "\n",
    "Получается хорошо знакомая нам функция [cross entropy](https://en.wikipedia.org/wiki/Cross_entropy) (если домножить на $-1$). Правдоподобие нужно максимизировать, а, соответственно, перекрестную энтропию нужно минимизировать. Продифференцировав по параметрам модели, мы _легко_ получим правила обновления весов для градиентного спуска, **проделайте этот вывод, если вы его не делали** (если вы вдруг сдались, то на [этом](https://www.youtube.com/watch?v=-WiR16raQf4) видео есть разбор вывода, понимание этого вам понадобится для дальнейшего выполнения задания):\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} &=& x_m \\left(y_k - \\sigma_k\\left(\\vec{z}\\right)\\right)\n",
    "\\end{array}$$\n",
    "\n",
    "В стандартной формулировке получается, что вектор $\\left(\\sigma_1, \\sigma_2, \\ldots, \\sigma_K\\right)$ образует дискретное вероятностное распределение, т.е. $\\sum_{i=1}^K \\sigma_i = 1$. Но в нашей постановке задачи каждый пример может иметь несколько тегов или одновременно принадлежать к нескольким классам. Для этого мы немного изменим модель:\n",
    "- будем считать, что все теги независимы друг от друга, т.е. каждый исход – это логистическая регрессия на два класса (либо есть тег, либо его нет), тогда вероятность наличия тега у примера запишется следующим образом (каждый тег/класс как и в многоклассовой логрегрессии имеет свой набор параметров):\n",
    "$$\\large p\\left(\\text{tag}_k \\mid \\vec{x}\\right) = \\sigma\\left(z_k\\right) = \\sigma\\left(\\sum_{i=1}^M w_{ki} x^i \\right)$$\n",
    "- наличие каждого тега мы будем моделировать с помощью <a href=\"https://en.wikipedia.org/wiki/Bernoulli_distribution\">распределения Бернулли</a>\n",
    "\n",
    "Ваше первое задание –  записать упрощенное выражение логарифма правдоподобия примера с признаками $\\vec{x}$. Как правило, многие алгоритмы оптимизации имеют интерфейс для минимизации функции, мы последуем этой же традиции, и домножим полученное выражение на $-1$, а во второй части выведем формулы для минимизации полученного выражения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. $\\large -\\mathcal{L} = -\\sum_{i=1}^M y_i \\log \\sigma\\left(z_i\\right) + \\left(1 - y_i\\right) \\log \\left(1 - \\sigma\\left(z_i\\right)\\right)$\n",
    "2. <font color='green'>$\\large -\\mathcal{L} = -\\sum_{i=1}^K y_i \\log \\sigma\\left(z_i\\right) + \\left(1 - y_i\\right) \\log \\left(1 - \\sigma\\left(z_i\\right)\\right)$</font>\n",
    "3. $\\large -\\mathcal{L} = -\\sum_{i=1}^K z_i \\log \\sigma\\left(y_i\\right) + \\left(1 - z_i\\right) \\log \\left(1 - \\sigma\\left(y_i\\right)\\right)$\n",
    "4. $\\large -\\mathcal{L} = -\\sum_{i=1}^M z_i \\log \\sigma\\left(y_i\\right) + \\left(1 - z_i\\right) \\log \\left(1 - \\sigma\\left(y_i\\right)\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Вывод формулы обновления весов\n",
    "\n",
    "В качестве второго задания вам предоставляется возможность вывести формулу градиента для $-\\mathcal{L}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Варианты ответа:</font>:\n",
    "1. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = -x_m \\left(\\sigma\\left(z_k\\right) - y_k\\right)$\n",
    "2. <font color='green'>$\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = -x_m \\left(y_k - \\sigma\\left(z_k\\right)\\right)$</font>\n",
    "3. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = \\left(\\sigma\\left(z_k\\right)x_m - y_k\\right)$\n",
    "4. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = \\left(y_k - \\sigma\\left(z_k\\right)x_m\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Имплементация базовой модели\n",
    "\n",
    "Вам предлагается каркас класса модели, разберите его внимательно, обращайте внимание на комментарии. Затем заполните пропуски, запустите полученную модель и ответьте на проверочный вопрос.\n",
    "\n",
    "Как вы могли уже заметить, при обновлении веса $w_{km}$ используется значение признака $x_m$, который равен $0$ если слова с индексом $m$ нет в предложении, и больше нуля, если такое слово есть. Соответственно, при вычислении линейной комбинации $z$ весов модели и признаков примера необходимо учитывать только ненулевые признаки объекта.\n",
    "\n",
    "Подсказка:\n",
    "- если реализовывать вычисление сигмоида так же, как в формуле, то при большом отрицательном значении $z$ вычисление $e^{-z}$ превратится в очень большое число, которое вылетит за допустимые пределы\n",
    "- в то же время $e^{-z}$ от большого положительного $z$ будет нулем\n",
    "- воспользуйтесь свойствами функции $\\sigma$ для того, чтобы пофиксить эту ошибку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = -800\n",
    "1. / (1. + np.exp(- s)) if np.exp(s) != 0 else 0. # мой код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LogRegressor():\n",
    "    \n",
    "    \"\"\"Конструктор\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    top_tags : list of string, default=top_tags\n",
    "        список тегов\n",
    "    \"\"\"\n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # словарь который содержит мапинг слов предложений и тегов в индексы (для экономии памяти)\n",
    "        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "        self._vocab = {}\n",
    "        \n",
    "        # параметры модели: веса\n",
    "        # для каждого класса/тега нам необходимо хранить собственный вектор весов\n",
    "        # по умолчанию у нас все веса будут равны нулю\n",
    "        # мы заранее не знаем сколько весов нам понадобится\n",
    "        # поэтому для каждого класса мы создаем словарь изменяемого размера со значением по умолчанию 0\n",
    "        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        \n",
    "        # параметры модели: смещения или вес w_0\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        \n",
    "        self._tags = set(tags)\n",
    "    \n",
    "    \"\"\"Один прогон по датасету\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    fname : string, default=DS_FILE_NAME\n",
    "        имя файла с данными\n",
    "        \n",
    "    top_n_train : int\n",
    "        первые top_n_train строк будут использоваться для обучения, остальные для тестирования\n",
    "        \n",
    "    total : int, default=10000000\n",
    "        информация о количестве строк в файле для вывода прогресс бара\n",
    "    \n",
    "    learning_rate : float, default=0.1\n",
    "        скорость обучения для градиентного спуска\n",
    "        \n",
    "    tolerance : float, default=1e-16\n",
    "        используем для ограничения значений аргумента логарифмов\n",
    "    \"\"\"\n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16):\n",
    "        \n",
    "        self._loss = []\n",
    "        n = 0\n",
    "        \n",
    "        # откроем файл\n",
    "        with open(fname, 'r') as f:            \n",
    "            \n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                # значение функции потерь для текущего примера\n",
    "                sample_loss = 0\n",
    "\n",
    "                # прокидываем градиенты для каждого тега\n",
    "                for tag in self._tags:\n",
    "                    # целевая переменная равна 1 если текущий тег есть у текущего примера\n",
    "                    y = int(tag in tags)\n",
    "                    \n",
    "                    # расчитываем значение линейной комбинации весов и признаков объекта\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    z = self._b[tag] # мой код\n",
    "   \n",
    "                    for word in sentence:\n",
    "                        # если в режиме тестирования появляется слово которого нет в словаре, то мы его игнорируем\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                        z += self._w[tag][self._vocab[word]] # мой код\n",
    "    \n",
    "                    # вычисляем вероятность наличия тега\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    sigma = 1. / (1. + np.exp(- z)) if np.exp(z) != 0 else 0. # мой код\n",
    "    \n",
    "                    \n",
    "                    # обновляем значение функции потерь для текущего примера\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    sample_loss += - (y * np.log(sigma) + (1. - y) * np.log(1. - sigma)) # мой код\n",
    "                 \n",
    "                    \n",
    "                    # если мы все еще в тренировочной части, то обновим параметры\n",
    "                    if n < top_n_train:\n",
    "                        # вычисляем производную логарифмического правдоподобия по весу\n",
    "                        # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                        dLdw = (y - sigma)\n",
    "\n",
    "                        # делаем градиентный шаг\n",
    "                        # мы минимизируем отрицательное логарифмическое правдоподобие (второй знак минус)\n",
    "                        # поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\n",
    "                        for word in sentence:                        \n",
    "                            self._w[tag][self._vocab[word]] -= -learning_rate*dLdw\n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                    \n",
    "                n += 1\n",
    "                        \n",
    "                self._loss.append(sample_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6084b9f8d16846eba7c2c970a46fe640"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:98: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:98: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:93: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# создадим эксемпляр модели и пройдемся по датасету\n",
    "model = LogRegressor()\n",
    "model.iterate_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, действительно ли значение отрицательного логарифмического правдоподобия уменьшалось. Так как мы используем стохастический градентный спуск, не стоит ожидать плавного падения функции ошибки. Мы воспользуемся скользящим средним с окном в 10 000 примеров, чтобы хоть как то сгладить график."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6sAAAKqCAYAAADcyciUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEasAAACk8//ko1wMcL/JLAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fb69a55908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the loss function on the last 10k train samples: nan\n"
     ]
    }
   ],
   "source": [
    "print('Mean of the loss function on the last 10k train samples: %0.2f' % np.mean(model._loss[-35000:-25000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычислите среднее значение функции стоимости на последних 10 000 примеров тренировочного набора, к какому из значений ваш ответ ближе всего?\n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>:\n",
    "1. 17.54\n",
    "2. 18.64\n",
    "3. 19.74\n",
    "4. 20.84"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4. Тестирование модели\n",
    "\n",
    "В базовой модели первые 100 000 строк используются для обучения, а оставшиеся – для тестирования. Как вы можете заметить, значение отрицательного логарифмического правдоподобия не очень информативно, хоть и позволяет сравнивать разные модели. В качестве четвертого задания вам необходимо модифицировать базовую модель таким образом, чтобы метод `iterate_file` возвращал значение _точности_ на тестовой части набора данных. \n",
    "\n",
    "Точность определим следующим образом:\n",
    "- считаем, что тег у вопроса присутствует, если спрогнозированная вероятность тега больше 0.9\n",
    "- точность одного примера расчитывается как [коэффициент Жаккара](https://ru.wikipedia.org/wiki/Коэффициент_Жаккара) между множеством настоящих тегов и предсказанных моделью\n",
    "  - например, если у примера настоящие теги ['html', 'jquery'], а по версии модели ['ios', 'html', 'java'], то коэффициент Жаккара будет равен |['html', 'jquery'] $\\cap$ ['ios', 'html', 'java']| / |['html', 'jquery'] $\\cup$ ['ios', 'html', 'java']| = |['html']| / |['jquery', 'ios', 'html', 'java']| = 1/4\n",
    "- метод `iterate_file` возвращает **среднюю** точность на тестовом наборе данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "# выведем полученное значение с точностью до двух знаков\n",
    "print('%0.2f' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Ответьте на вопрос,  к какому значению ближе всего полученное значение точности?\n",
    "<font color=\"red\">Варианты ответа:</font>:\n",
    "1. 0.39\n",
    "2. 0.49\n",
    "3. 0.59\n",
    "4. 0.69"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5. $L_2$-регуляризация\n",
    "\n",
    "В качестве пятого задания вам необходимо добавить в класс `LogRegressor` поддержку $L_2$-регуляризации. В методе `iterate_file` должен появиться параметр `lmbda=0.01` со значением по умолчанию. С учетом регуляризации новая функция стоимости примет вид:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\frac{\\lambda}{2} R\\left(W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\frac{\\lambda}{2} \\sum_{k=1}^K\\sum_{i=1}^M w_{ki}^2\n",
    "\\end{array}$$\n",
    "\n",
    "Градиент первого члена суммы мы уже вывели, а для второго он имеет вид:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\frac{\\partial}{\\partial w_{ki}} \\frac{\\lambda}{2} R\\left(W\\right) &=& \\lambda w_{ki}\n",
    "\\end{array}$$\n",
    "\n",
    "Если мы на каждом примере будем делать честное обновление всех весов, то все очень замедлится, ведь нам придется на каждой итерации пробегать по всем словам словаря. В ущерб теоретической точности вы используем грязный трюк: мы будем регуляризаровать только те слова, которые присутствуют в текущем предложении. Не забывайте, что смещение не регуляризируется. `sample_loss` тоже должен остаться без изменений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ответьте на вопрос, к какому значению ближе всего полученное значение точности?\n",
    "<font color=\"red\">Варианты ответа:</font>:\n",
    "1. 0.3\n",
    "2. 0.35\n",
    "3. 0.4\n",
    "4. 0.52"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ElasticNet регуляризация, вывод\n",
    "Помимо $L_2$ регуляризации, часто используется $L_1$ регуляризация.\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\frac{\\lambda}{2} R\\left(W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\lambda \\sum_{k=1}^K\\sum_{i=1}^M \\left|w_{ki}\\right|\n",
    "\\end{array}$$\n",
    "\n",
    "Если линейно объединить $L_1$ и $L_2$ регуляризацию, то полученный тип регуляризации называется ElasticNet:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\lambda R\\left(W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\lambda \\left(\\gamma \\sum_{k=1}^K\\sum_{i=1}^M w_{ki}^2 + \\left(1 - \\gamma\\right) \\sum_{k=1}^K\\sum_{i=1}^M \\left|w_{ki}\\right| \\right)\n",
    "\\end{array}$$\n",
    "- где $\\gamma \\in \\left[0, 1\\right]$\n",
    "\n",
    "В качестве шестого вопроса вам предлагается вывести формулу градиента ElasticNet регуляризации (не учитывая $-\\mathcal{L}$). \n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>:\n",
    "1. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(2 \\gamma w_{ki} + \\left(1 - \\gamma\\right) w_{ki}\\right)$ \n",
    "2. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(2 \\gamma \\left|w_{ki}\\right| + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$\n",
    "3. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(2 \\gamma w_{ki} + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$\n",
    "4. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(\\gamma w_{ki} + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ElasticNet регуляризация, имплементация\n",
    "\n",
    "В качестве седьмой задачи, вам предлается изменить класс `LogRegressor` таким образом, чтобы метод `iterate_file` принимал два параметра со значениями по умолчанию `lmbda=0.0002` и `gamma=0.1`. Сделайте один проход по датасету с включенной ElasticNet регуляризацией и заданными значениями по умолчанию и ответьте на вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Ответьте на вопрос,  к какому значению ближе всего полученное значение точности:\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.59\n",
    "2. 0.69\n",
    "3. 0.79\n",
    "4. 0.82"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Самые важные слова для тега\n",
    "\n",
    "Прелесть линейных моделей в том, что они легко интерпретируемы. Вам предлагается вычислить, какие слова вносят наибольший вклад в вероятность каждого из тегов. А затем ответьте на контрольный вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для многих тегов наличие самого тега в предложении является важным сигналом, у многих сам тег является самым сильным сигналом, что неудивительно. Для каких из тегов само название тега не входит в топ-5 самых важных?\n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. java, c#\n",
    "2. php, javascript\n",
    "3. html, jquery\n",
    "4. ios, android"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 9. Сокращаем размер словаря\n",
    "Сейчас количество слов в словаре - 519290, если бы это была выборка из 10 миллионов вопросов с сайта StackOverflow, то размер словаря был бы миллионов 10. Регуляризировать модель можно не только изящно математически, но и топорно, например, ограничить размер словаря. Вам предоставляется возможность внести следующие изменения в класс `LogRegressor`:\n",
    "- добавить в метод `iterate_file` еще один аргумент со значением по умолчанию `update_vocab=True`\n",
    "- при `update_vocab=True` разрешать добавлять слова в словарь в режиме обучения\n",
    "- при `update_vocab=False` игнорировать слова не из словаря\n",
    "- добавить в класс метод `filter_vocab(n=10000)`, который оставит в словаре только топ-n самых популярных слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file(update_vocab=True)\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# оставим только топ 10 000 слов\n",
    "model.filter_vocab(n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# сделаем еще одну итерацию по датасету, уменьшив скорость обучения в 10 раз\n",
    "acc = model.iterate_file(update_vocab=False, learning_rate=0.01)\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Ответьте на вопрос,  к какому значению ближе всего полученное значение точности:\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.48\n",
    "2. 0.58\n",
    "3. 0.68\n",
    "4. 0.78"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Прогнозирование тегов для новых вопросов\n",
    "\n",
    "В завершение сегодняшней домашки, вам предлагается реализовать метод `predict_proba`, который принимает строку,  содержащую вопрос, а возвращает список предсказанных тегов вопроса с их вероятностями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file(update_vocab=True)\n",
    "print('%0.2f' % acc)\n",
    "model.filter_vocab(n=10000)\n",
    "acc = model.iterate_file(update_vocab=False, learning_rate=0.01)\n",
    "print('%0.2f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence = (\"I want to improve my coding skills, so I have planned write \" +\n",
    "            \"a Mobile Application.need to choose between Apple's iOS or Google's Android.\" +\n",
    "            \" my background: I have done basic programming in .Net,C/C++,Python and PHP \" +\n",
    "            \"in college, so got OOP concepts covered. about my skill level, I just know \" +\n",
    "            \"concepts and basic syntax. But can't write complex applications, if asked :(\" +\n",
    "            \" So decided to hone my skills, And I wanted to know which is easier to \" +\n",
    "            \"learn for a programming n00b. A) iOS which uses Objective C B) Android \" + \n",
    "            \"which uses Java. I want to decide based on difficulty level\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ответьте на вопрос, какой или какие теги ассоциируются с данным вопросом, если порог принятия равен $0.9$?:\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. android\n",
    "2. ios\n",
    "3. ios, php\n",
    "4. c#, c++, ods"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
